{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURE</th>\n",
       "      <th>RAINFALL(cm)</th>\n",
       "      <th>HUMIDITY(%)</th>\n",
       "      <th>SOIL</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.37</td>\n",
       "      <td>97.87</td>\n",
       "      <td>54.54</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.46</td>\n",
       "      <td>170.65</td>\n",
       "      <td>56.47</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.83</td>\n",
       "      <td>208.49</td>\n",
       "      <td>69.81</td>\n",
       "      <td>loamy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.57</td>\n",
       "      <td>139.99</td>\n",
       "      <td>60.01</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.26</td>\n",
       "      <td>61.90</td>\n",
       "      <td>53.81</td>\n",
       "      <td>clay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMPERATURE  RAINFALL(cm)  HUMIDITY(%)      SOIL  Target\n",
       "0        17.37         97.87        54.54  alluvial       0\n",
       "1        25.46        170.65        56.47  alluvial       3\n",
       "2        26.83        208.49        69.81     loamy       2\n",
       "3        24.57        139.99        60.01  alluvial       3\n",
       "4        24.26         61.90        53.81      clay       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing dataset\n",
    "df = pd.read_csv('final_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding the Soil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "X['SOIL'] = labelencoder.fit_transform(X['SOIL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding the dependent and independent variables.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "onehotencoder2 = OneHotEncoder()\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "y = onehotencoder2.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Necessary imports for Deep Learning\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 01:07:48.935223  8372 deprecation_wrapper.py:119] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1015 01:07:48.950180  8372 deprecation_wrapper.py:119] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1015 01:07:48.952176  8372 deprecation_wrapper.py:119] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Layers of Deep Learning\n",
    "model = models.Sequential()\n",
    "model.add(Dense(16,activation='relu', input_dim=7))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                204       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 744\n",
      "Trainable params: 744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 01:07:49.356781  8372 deprecation_wrapper.py:119] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1015 01:07:49.381740  8372 deprecation_wrapper.py:119] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 01:07:49.467517  8372 deprecation.py:323] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1015 01:07:49.531316  8372 deprecation_wrapper.py:119] From c:\\users\\sahaj oberoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "280/280 [==============================] - 0s 1ms/step - loss: 2.4872 - acc: 0.2571\n",
      "Epoch 2/45\n",
      "280/280 [==============================] - 0s 89us/step - loss: 1.1191 - acc: 0.4536\n",
      "Epoch 3/45\n",
      "280/280 [==============================] - 0s 93us/step - loss: 0.9446 - acc: 0.6107\n",
      "Epoch 4/45\n",
      "280/280 [==============================] - 0s 107us/step - loss: 0.8044 - acc: 0.6964\n",
      "Epoch 5/45\n",
      "280/280 [==============================] - 0s 103us/step - loss: 0.7265 - acc: 0.7821\n",
      "Epoch 6/45\n",
      "280/280 [==============================] - 0s 93us/step - loss: 0.6721 - acc: 0.7679\n",
      "Epoch 7/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.6260 - acc: 0.7857\n",
      "Epoch 8/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.5738 - acc: 0.7857\n",
      "Epoch 9/45\n",
      "280/280 [==============================] - 0s 93us/step - loss: 0.5350 - acc: 0.8500\n",
      "Epoch 10/45\n",
      "280/280 [==============================] - 0s 103us/step - loss: 0.5273 - acc: 0.8036\n",
      "Epoch 11/45\n",
      "280/280 [==============================] - 0s 107us/step - loss: 0.4811 - acc: 0.8571\n",
      "Epoch 12/45\n",
      "280/280 [==============================] - 0s 93us/step - loss: 0.4642 - acc: 0.8464\n",
      "Epoch 13/45\n",
      "280/280 [==============================] - 0s 85us/step - loss: 0.4416 - acc: 0.8643\n",
      "Epoch 14/45\n",
      "280/280 [==============================] - 0s 92us/step - loss: 0.4356 - acc: 0.8429\n",
      "Epoch 15/45\n",
      "280/280 [==============================] - 0s 114us/step - loss: 0.4325 - acc: 0.8464\n",
      "Epoch 16/45\n",
      "280/280 [==============================] - 0s 89us/step - loss: 0.4019 - acc: 0.8643\n",
      "Epoch 17/45\n",
      "280/280 [==============================] - 0s 96us/step - loss: 0.3726 - acc: 0.8821\n",
      "Epoch 18/45\n",
      "280/280 [==============================] - 0s 96us/step - loss: 0.4077 - acc: 0.8464\n",
      "Epoch 19/45\n",
      "280/280 [==============================] - 0s 110us/step - loss: 0.3755 - acc: 0.8750\n",
      "Epoch 20/45\n",
      "280/280 [==============================] - 0s 121us/step - loss: 0.3641 - acc: 0.8571\n",
      "Epoch 21/45\n",
      "280/280 [==============================] - 0s 93us/step - loss: 0.3667 - acc: 0.8464\n",
      "Epoch 22/45\n",
      "280/280 [==============================] - 0s 103us/step - loss: 0.3486 - acc: 0.8714\n",
      "Epoch 23/45\n",
      "280/280 [==============================] - 0s 118us/step - loss: 0.3294 - acc: 0.8750\n",
      "Epoch 24/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.3450 - acc: 0.8536\n",
      "Epoch 25/45\n",
      "280/280 [==============================] - 0s 114us/step - loss: 0.3058 - acc: 0.9036\n",
      "Epoch 26/45\n",
      "280/280 [==============================] - 0s 107us/step - loss: 0.3133 - acc: 0.8750\n",
      "Epoch 27/45\n",
      "280/280 [==============================] - 0s 96us/step - loss: 0.4143 - acc: 0.8179\n",
      "Epoch 28/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2959 - acc: 0.8893\n",
      "Epoch 29/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2914 - acc: 0.8893\n",
      "Epoch 30/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2696 - acc: 0.9107\n",
      "Epoch 31/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2897 - acc: 0.8929\n",
      "Epoch 32/45\n",
      "280/280 [==============================] - 0s 135us/step - loss: 0.2970 - acc: 0.8893\n",
      "Epoch 33/45\n",
      "280/280 [==============================] - 0s 118us/step - loss: 0.3020 - acc: 0.8857\n",
      "Epoch 34/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2867 - acc: 0.8786\n",
      "Epoch 35/45\n",
      "280/280 [==============================] - 0s 89us/step - loss: 0.2610 - acc: 0.9036\n",
      "Epoch 36/45\n",
      "280/280 [==============================] - 0s 96us/step - loss: 0.3101 - acc: 0.8821\n",
      "Epoch 37/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2522 - acc: 0.9214\n",
      "Epoch 38/45\n",
      "280/280 [==============================] - 0s 85us/step - loss: 0.2536 - acc: 0.8964\n",
      "Epoch 39/45\n",
      "280/280 [==============================] - 0s 103us/step - loss: 0.2669 - acc: 0.8964\n",
      "Epoch 40/45\n",
      "280/280 [==============================] - 0s 96us/step - loss: 0.2541 - acc: 0.9143\n",
      "Epoch 41/45\n",
      "280/280 [==============================] - 0s 114us/step - loss: 0.2367 - acc: 0.9143\n",
      "Epoch 42/45\n",
      "280/280 [==============================] - 0s 96us/step - loss: 0.2330 - acc: 0.8929\n",
      "Epoch 43/45\n",
      "280/280 [==============================] - 0s 100us/step - loss: 0.2300 - acc: 0.9143\n",
      "Epoch 44/45\n",
      "280/280 [==============================] - 0s 103us/step - loss: 0.2253 - acc: 0.9107\n",
      "Epoch 45/45\n",
      "280/280 [==============================] - 0s 107us/step - loss: 0.2455 - acc: 0.9071\n"
     ]
    }
   ],
   "source": [
    "final_model = model.fit(X_train, y_train, epochs=45, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(final_model.history['acc'])\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model and weights together. \n",
    "models.save_model(model, 'total.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4964"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting keras model to tensorflow lite for android\n",
    "from tensorflow import lite\n",
    "converter = lite.TocoConverter.from_keras_model_file('total.h5')\n",
    "tflite_model = converter.convert()\n",
    "open('final.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving model and its weights\n",
    "# import json\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "    \n",
    "# model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading the saved model and weights\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "\n",
    "# from keras.models import model_from_json\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    " \n",
    "# # evaluate loaded model on test data\n",
    "# loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
